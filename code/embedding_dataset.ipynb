{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c0b85c6",
   "metadata": {},
   "source": [
    "### embedding_dataset.pt 파일 생성하는 함수\n",
    "동우님이 주신 것과 버전 호환성 문제가 생겨서 다시 만드는 파일을 임의로 추가했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e54fe17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jhg-pc-02\\Documents\\TextMining\\TextMining\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labeled.csv 파일 로딩 중...\n",
      "총 8000개의 데이터 로드됨\n",
      "데이터 구조:\n",
      "               filename label  \\\n",
      "0  001_개인정보취급방침_가공.json    유리   \n",
      "1   001_결혼정보서비스_가공.json    유리   \n",
      "2        001_보증_가공.json    유리   \n",
      "3      001_사이버몰_가공.json    유리   \n",
      "4      001_상해보험_가공.json    유리   \n",
      "\n",
      "                                                text basis  \n",
      "0  제2조(개인정보의 처리 및 보유기간) \\n① 협회는 법령에 따른 개인정보 보유․이용...   NaN  \n",
      "1  제3조 (회원가입)\\n① 회원이 되려고 하는 사람은 결혼관련 개인정보를 회사에 제공...   NaN  \n",
      "2  제2조(보증금액)\\n ① 이 보증서에 의한 보증금액은 채권자의 채무자에 대한 보증부...   NaN  \n",
      "3  제3조 (약관 등의 명시와 설명 및 개정)\\n① 몰은 이 약관의 내용과 상호 및 대...   NaN  \n",
      "4  제4조(보험금 지급에 관한 세부규정)\\n② 제3조(보험금의 지급사유) 제2호에서 장...   NaN  \n",
      "컬럼: ['filename', 'label', 'text', 'basis']\n",
      "\n",
      "legal-kr-sbert-contrastive 모델 로딩 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jhg-pc-02\\Documents\\TextMining\\TextMining\\.venv\\lib\\site-packages\\torch\\cuda\\__init__.py:129: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10\\cuda\\CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델이 cpu에 로드됨\n",
      "\n",
      "임베딩할 텍스트 개수: 8000\n",
      "텍스트 임베딩 생성 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [17:53<00:00,  4.29s/it]\n",
      "C:\\Users\\jhg-pc-02\\AppData\\Local\\Temp\\ipykernel_16284\\66844664.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_dataset = torch.load('embedding_dataset.pt', map_location='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임베딩 생성 완료: torch.Size([8000, 384])\n",
      "\n",
      "embedding_dataset.pt 파일 저장 중...\n",
      "저장 완료!\n",
      "\n",
      "저장된 파일 검증...\n",
      "텍스트 개수: 8000\n",
      "임베딩 크기: torch.Size([8000, 384])\n",
      "메타데이터 키: dict_keys(['filenames', 'labels', 'basis'])\n",
      "검증 완료!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. 데이터 로드\n",
    "print(\"labeled.csv 파일 로딩 중...\")\n",
    "try:\n",
    "    labeled_df = pd.read_csv('labeled.csv', encoding='utf-8')\n",
    "except UnicodeDecodeError:\n",
    "    # 인코딩 문제가 있는 경우 다른 인코딩 시도\n",
    "    labeled_df = pd.read_csv('labeled.csv', encoding='cp949')\n",
    "\n",
    "print(f\"총 {len(labeled_df)}개의 데이터 로드됨\")\n",
    "print(\"데이터 구조:\")\n",
    "print(labeled_df.head())\n",
    "print(f\"컬럼: {labeled_df.columns.tolist()}\")\n",
    "\n",
    "# 2. 모델 로드\n",
    "print(\"\\nlegal-kr-sbert-contrastive 모델 로딩 중...\")\n",
    "semantic_dir = \"../model/legal-kr-sbert-contrastive\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "semantic_model = SentenceTransformer(semantic_dir).to(device)\n",
    "print(f\"모델이 {device}에 로드됨\")\n",
    "\n",
    "# 3. 텍스트 전처리 (필요시)\n",
    "texts = labeled_df['text'].fillna('').astype(str).tolist()\n",
    "print(f\"\\n임베딩할 텍스트 개수: {len(texts)}\")\n",
    "\n",
    "# 4. 배치 단위로 임베딩 생성 (메모리 효율성)\n",
    "batch_size = 32  # GPU 메모리에 따라 조정\n",
    "embeddings_list = []\n",
    "\n",
    "print(\"텍스트 임베딩 생성 중...\")\n",
    "for i in tqdm(range(0, len(texts), batch_size)):\n",
    "    batch_texts = texts[i:i+batch_size]\n",
    "    batch_embeddings = semantic_model.encode(\n",
    "        batch_texts,\n",
    "        convert_to_tensor=True,\n",
    "        device=device,\n",
    "        show_progress_bar=False\n",
    "    )\n",
    "    embeddings_list.append(batch_embeddings.cpu())\n",
    "\n",
    "# 5. 모든 임베딩 합치기\n",
    "embeddings = torch.cat(embeddings_list, dim=0)\n",
    "print(f\"임베딩 생성 완료: {embeddings.shape}\")\n",
    "\n",
    "# 6. 검색을 위한 데이터셋 구성\n",
    "dataset = {\n",
    "    'texts': texts,  # 원본 텍스트\n",
    "    'embeddings': embeddings,  # 임베딩 벡터\n",
    "    'metadata': {\n",
    "        'filenames': labeled_df['filename'].tolist(),\n",
    "        'labels': labeled_df['label'].tolist(),\n",
    "        'basis': labeled_df['basis'].tolist()\n",
    "    }\n",
    "}\n",
    "\n",
    "# 7. .pt 파일로 저장\n",
    "print(\"\\nembedding_dataset.pt 파일 저장 중...\")\n",
    "torch.save(dataset, 'embedding_dataset.pt')\n",
    "print(\"저장 완료!\")\n",
    "\n",
    "# 8. 저장된 파일 검증\n",
    "print(\"\\n저장된 파일 검증...\")\n",
    "loaded_dataset = torch.load('embedding_dataset.pt', map_location='cpu')\n",
    "print(f\"텍스트 개수: {len(loaded_dataset['texts'])}\")\n",
    "print(f\"임베딩 크기: {loaded_dataset['embeddings'].shape}\")\n",
    "print(f\"메타데이터 키: {loaded_dataset['metadata'].keys()}\")\n",
    "print(\"검증 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5a734d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
